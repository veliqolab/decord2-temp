name: Build and Publish to PyPI

on:
  push:
    branches: [ master ]
    tags:
      - "v*"
  pull_request:
    branches: [ master ]

jobs:
  build_wheels:
    name: Build CPU wheels on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            pybuilds: cp3{10,11,12,13,13t}-manylinux_x86_64
            arch: x86_64
            id: linux_x86_64
          - os: ubuntu-24.04-arm
            pybuilds: cp3{10,11,12,13,13t}-manylinux_aarch64
            arch: aarch64
            id: linux_aarch64
          - os: macos-13
            pybuilds: cp3{10,11,12,13,13t}-macosx_x86_64
            arch: x86_64
            id: macos_x86
          - os: macos-latest
            pybuilds: cp3{10,11,12,13,13t}-macosx_arm64
            arch: arm64
            id: macos_arm64

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Build source package
        if: matrix.os == 'ubuntu-latest'
        run: |
          pip install -U build cython setuptools
          python scripts/fetch-vendor.py --config-file scripts/ffmpeg-8.0.json /tmp/vendor
      - name: Upload source package
        if: matrix.os == 'ubuntu-latest'
        uses: actions/upload-artifact@v4
        with:
          name: dist-source
          path: dist/*.tar.gz

      - name: Install cibuildwheel and dependencies
        run: |
          python -m pip install --upgrade pip pytest cibuildwheel==v3.1.4

      - name: Set Minimum MacOS Target
        if: runner.os == 'macOS'
        run: |
          echo "MACOSX_DEPLOYMENT_TARGET=12.0" >> $GITHUB_ENV
      - name: Build wheels
        uses: pypa/cibuildwheel@v3.1.4
        with:
          package-dir: python
        env:
          CIBW_ARCHS_MACOS: ${{ matrix.arch }}
          OMPL_BUILD_ARCH: ${{ matrix.arch }}
          CIBW_BUILD: ${{ matrix.pybuilds }}
          CIBW_SKIP: "cp*-manylinux_i686 cp*-musllinux* cp*-win32 pp*"
          CIBW_TEST_SKIP: "cp311-* cp312-* cp313-* pp*"
          CIBW_BEFORE_BUILD_LINUX: |
            python scripts/fetch-vendor.py --config-file scripts/ffmpeg-8.0.json /tmp/vendor
            yum install -y epel-release
            yum install -y cmake make gcc gcc-c++ pkgconfig libbsd-devel soxr-devel alsa-lib-devel openssl-devel compat-openssl10
            rm -f /tmp/vendor/lib/libsoxr.so*
            mkdir build
            cd build
            cmake .. -DUSE_CUDA=OFF -DCMAKE_BUILD_TYPE=Release
            make -j$(nproc)
            cp libdecord.so ..
          CIBW_BEFORE_BUILD_MACOS: |
            python scripts/fetch-vendor.py --config-file scripts/ffmpeg-8.0.json /tmp/vendor
            brew install cmake
            mkdir build
            cd build
            cmake .. -DUSE_CUDA=OFF -DCMAKE_BUILD_TYPE=Release
            make -j$(sysctl -n hw.ncpu)
            cp libdecord.dylib ..
          CIBW_ENVIRONMENT_LINUX: LD_LIBRARY_PATH=/tmp/vendor/lib:$LD_LIBRARY_PATH PKG_CONFIG_PATH=/tmp/vendor/lib/pkgconfig
          CIBW_ENVIRONMENT_MACOS: PKG_CONFIG_PATH=/tmp/vendor/lib/pkgconfig LDFLAGS=-headerpad_max_install_names
          CIBW_TEST_COMMAND: python -m pytest {project}/tests/python/unittests -v
          CIBW_TEST_REQUIRES: pytest numpy nose simpleaudio

      - uses: actions/upload-artifact@v4
        with:
          name: wheels-${{ matrix.id }}
          path: ./wheelhouse/*.whl

  build_cuda_wheels:
    name: Build CUDA wheels on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: ubuntu-latest
            arch: x86_64
            pybuilds: "cp3{10,11,12,13,13t}-manylinux_x86_64"
            cuda_arch: "80;86;89;90;100;120"
            id: linux_x86_64_cuda
          - os: ubuntu-24.04-arm
            arch: aarch64
            pybuilds: "cp3{10,11,12,13,13t}-manylinux_aarch64"
            cuda_arch: "80;86;87;89;90;100;101;120"
            id: linux_aarch64_cuda

    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install cibuildwheel
        run: python -m pip install cibuildwheel==v3.1.4

      - name: Build wheels with CUDA
        uses: pypa/cibuildwheel@v3.1.4
        with:
          package-dir: python
        env:
          CIBW_BUILD: ${{ matrix.pybuilds }}
          CIBW_SKIP: "cp*-manylinux_i686 cp*-musllinux* cp*-win32 pp*"
          CIBW_MANYLINUX_X86_64_IMAGE: manylinux_2_28
          CIBW_MANYLINUX_AARCH64_IMAGE: manylinux_2_28
          CIBW_TEST_SKIP: "*"
          # BEFORE_ALL runs once per container.
          CIBW_BEFORE_ALL_LINUX: |
            set -ex
            # First, install the tool needed to add repositories
            yum install -y dnf-utils
            yum install -y cmake make gcc gcc-c++ pkgconfig libbsd-devel soxr-devel alsa-lib-devel compat-openssl10

            # Detect architecture and add the correct NVIDIA CUDA repo for RHEL 8-based manylinux
            ARCH=$(uname -m)
            if [ "$ARCH" == "x86_64" ]; then
              REPO_URL=https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo
            elif [ "$ARCH" == "aarch64" ]; then
              REPO_URL=https://developer.download.nvidia.com/compute/cuda/repos/rhel8/sbsa/cuda-rhel8.repo
            else
              echo "Unsupported architecture: $ARCH"
              exit 1
            fi

            echo "--- Adding CUDA repo for $ARCH ---"
            yum-config-manager --add-repo ${REPO_URL}
            yum clean all

            echo "--- Installing CUDA Toolkit and build dependencies ---"
            # Install specific CUDA version and other build tools
            dnf -y module install nvidia-driver:open-dkms
            yum install -y \
            cuda-compiler-13-0-13.0.0-1 \
            cuda-libraries-13-0-13.0.0-1 \
            cuda-libraries-devel-13-0-13.0.0-1 \
            cuda-toolkit-13-0-13.0.0-1 \
            cudnn
            yum install -y cmake make gcc gcc-c++ pkgconfig libbsd-devel soxr-devel alsa-lib-devel compat-openssl10
            echo "--- Installing GCC Toolset 11 ---"
            yum install -y gcc-toolset-11

            # Enable the GCC 11 toolset for the rest of this script
            source /opt/rh/gcc-toolset-11/enable

            echo "--- Verifying CUDA installation ---"
            # The 'export' is not needed here as the CIBW_ENVIRONMENT_LINUX var will set the path later.
            # We just need to call it with the full path for verification.
            echo "--- Verifying GCC and CUDA installation ---"
            gcc --version
            /usr/local/cuda-13.0/bin/nvcc --version
          # BEFORE_BUILD runs for each python version.
          CIBW_BEFORE_BUILD_LINUX: |
            set -ex
            echo "--- Installing GCC Toolset 11 ---"
            yum install -y gcc-toolset-11
            source /opt/rh/gcc-toolset-11/enable
            python scripts/fetch-vendor.py --config-file scripts/ffmpeg-8.0.json /tmp/vendor
            rm -f /tmp/vendor/lib/libsoxr.so*

            # Use a fresh build directory for each Python version to prevent contamination.
            mkdir -p build && cd build
            echo "--- Running CMake with CUDA support ---"
            cmake .. \
              -DUSE_CUDA=ON \
              -DCMAKE_BUILD_TYPE=Release \
              -DCUDAToolkit_ROOT=/usr/local/cuda-13.0 \
              -DCMAKE_CUDA_ARCHITECTURES="${{ matrix.cuda_arch }}"
            echo "--- Building with make ---"
            make -j$(nproc)
            cp libdecord.so ..
          # Set environment variables for the build process inside the container
          CIBW_ENVIRONMENT_LINUX: >
            PATH=/usr/local/cuda-13.0/bin:$PATH
            LD_LIBRARY_PATH=/usr/local/cuda-13.0/lib64:/tmp/vendor/lib:$LD_LIBRARY_PATH
            PKG_CONFIG_PATH=/tmp/vendor/lib/pkgconfig
          CUDA_TAG: "cu130"

      - name: Rename wheels for CUDA version
        shell: bash
        env:
          CUDA_TAG: "cu130"
          ARCH: ${{ matrix.arch }}
        run: |
          set -e
          cd ./wheelhouse
          echo "--- Original wheels ---"
          ls -1
          echo "--- Renaming wheels for CUDA version ${CUDA_TAG} ---"
          for wheel in ./*.whl; do
              [[ -e "$wheel" ]] || continue
              base=$(basename "$wheel")
              version=$(echo "$base" | grep -oP '(?<=decord2-)[^-]+')
              pyver=$(echo "$base" | grep -oP 'cp3[0-9]+-cp3[0-9]+')
              platform_tag="manylinux_2_28_${ARCH}"
              new_name="decord2-${version}+${CUDA_TAG}-${pyver}-${platform_tag}.whl"
              echo "Renaming '$base' â†’ '$new_name'"
              mv "$wheel" "$new_name"
          done
          echo "--- Renamed wheels ---"
          ls -1
      - uses: actions/upload-artifact@v4
        with:
          name: wheels-${{ matrix.id }}
          path: ./wheelhouse/*.whl

  publish:
    name: Publish to PyPI
    needs: [build_wheels, build_cuda_wheels]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags/')
    environment:
      name: release
      url: https://pypi.org/p/decord2
    permissions:
      id-token: write
    steps:
      - name: Download all wheels and sdist
        uses: actions/download-artifact@v4
        with:
          path: ./dist
          merge-multiple: true

      - name: List downloaded files
        run: ls -R ./dist

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          skip_existing: true